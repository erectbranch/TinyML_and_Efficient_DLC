# 7 Neural Architecture Search (Part I)

> [Lecture 07 - Neural Architecture Search (Part I) | MIT 6.S965](https://www.youtube.com/watch?v=NQj5TkqX48Q)

> [AutoML ê¸°ìˆ  ë™í–¥](https://ettrends.etri.re.kr/ettrends/178/0905178004/34-4_32-42.pdf2)

AutoML(ìë™ê¸°ê³„í•™ìŠµ)ì—ì„œëŠ” í¬ê²Œ ì„¸ ê°€ì§€ processë¥¼ ìë™í™”í•˜ëŠ” ë° ì¤‘ì ì„ ë‘”ë‹¤.

![AutoML](images/autoML.png)

- **feature engineering**

    domain knowledgeë¥¼ ë°”íƒ•ìœ¼ë¡œ featureë¥¼ ë§Œë“œëŠ” ê³¼ì •ì´ë‹¤.

- **Hyper-Parameter Optimization**(HPO)

    HPOëŠ” **meta-optimization**ìœ¼ë¡œ, hyperparameter ìì²´ë¥¼ ìë™ìœ¼ë¡œ optimizationí•œë‹¤.

    > hyperparameter: learning rate, lr scheduling, loss function, epoch, weight initialization, normalization, \#layers ë“±

- **Neural Architecture Search**(NAS)

  ìµœì ì˜ model architectureë¥¼ ìë™ìœ¼ë¡œ íƒìƒ‰í•œë‹¤.

  - Evolutionary Algorithms(ì§„í™” ì•Œê³ ë¦¬ì¦˜) ê¸°ë°˜ íƒìƒ‰(AmeobaNet ë“±)
  
  - Reinforcement Learning(ê°•í™” í•™ìŠµ) ê¸°ë°˜ íƒìƒ‰(NASNet ë“±)

  - Gradient Descent ê¸°ë°˜ íƒìƒ‰

ì´ì¤‘ì—ì„œë„ Neural Architecture Search(NAS)ë¥¼ ì¤‘ì ì ìœ¼ë¡œ ì‚´í´ë³¼ ê²ƒì´ë‹¤.

---

## 7.1 Basic Concepts

---

### 7.1.1 Stages

Neural Network architectureëŠ” input stem, head, ê·¸ë¦¬ê³  ì—¬ëŸ¬ stageë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.

![input stem, head, stages](images/stage.png)

- **Input Stem** 

  ê°€ì¥ í° resolution inputì„ ê°–ëŠ” ë¶€ë¶„ìœ¼ë¡œ, aggressiveí•˜ê²Œ downsamplingì„ ìˆ˜í–‰í•œë‹¤.
  
  ì˜ˆì‹œì—ì„œëŠ” resolutionì„ ( $56 \times 56$ )ìœ¼ë¡œ downsamplingí•œë‹¤.

  - í° receptive fieldë¥¼ ì–»ê¸° ìœ„í•´, ëŒ€ì²´ë¡œ large kernel( $7 \times 7$ )ì„ ì‚¬ìš©í•œë‹¤.

  - channel ìˆ˜ê°€ 3ê°œë¡œ ë§¤ìš° ì ê¸° ë•Œë¬¸ì—, ê³„ì‚°ì´ ë§ì´ í•„ìš”í•˜ì§€ëŠ” ì•Šë‹¤.

- **Stage**

  ê° stage ë‚´ë¶€ì—ì„œëŠ” input resolutionì´ ë™ì¼í•˜ë‹¤.

  - early stage: large feature map sizeë¥¼ ê°–ëŠ”ë‹¤.(activation memoryê°€ ë§ì´ í•„ìš”í•˜ë‹¤.)

  - late stage: small feature map sizeë¥¼ ê°–ëŠ”ë‹¤.

    ë”°ë¼ì„œ ê·¸ë§Œí¼ width(\#channels)ë¥¼ ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤.

- **head**

  **application-specific**í•œ ë¶€ë¶„ìœ¼ë¡œ detection head, segmentation head ë“±ì´ ìœ„ì¹˜í•˜ê²Œ ëœë‹¤.

---

### 7.1.2 Downsampling, Residual/Skip connection

![downsample](images/downsample.png)

- ëŒ€ì²´ë¡œ ê° stageì˜ first blockì—ì„œ **feature map downsampling**ì„ ìˆ˜í–‰í•œë‹¤. 

  stride convolution í˜¹ì€ poolingì„ í†µí•´ downsamplingì„ ìˆ˜í–‰í•œë‹¤.

- ë‚˜ë¨¸ì§€ blocksì—ì„œëŠ” input, output dimensionsì´ ë™ì¼í•˜ë¯€ë¡œ **residual/skip connection**ì„ ë”í•´ì¤„ ìˆ˜ ìˆë‹¤.

---

## 7.2 manually-designed neural network

---

### 7.2.1 AlexNet, VGGNet

- **AlexNet**(2012)

  ![AlexNet](images/AlexNet_arch.png)

  íŠ¹ì§•ìœ¼ë¡œ ealry stageì—ì„œ í° kernelì„ ì‚¬ìš©í•œë‹¤.
  
  - $11 \times 11$ (channel 96) , ê·¸ ë‹¤ìŒì€ $5 \times 5$ (channel 256)

- **VGGNet**(2014)

  ë°˜ë©´ VGGNetì€ early stageì—ì„œ ì‘ì€ kernelì„ ì—¬ëŸ¬ ê°œ ìŒ“ì•„ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì–»ì—ˆë‹¤.

  ![VGGNet](images/VGGNet_arch.png)

  - ì˜¤ì§ $3 \times 3$ convolutionì„ ì‚¬ìš©í•œë‹¤. 
  
  - í•œ stageì—ì„œ $3 \times 3$ ë ˆì´ì–´ë¥¼ ë‘ ê°œ ìŒ“ëŠ” ê²ƒì´( $3 \times 3 + 3 \times 3 = 18$ parameters ),  $5 \times 5$ (=25 parameters) ë ˆì´ì–´ í•˜ë‚˜ë³´ë‹¤ computational costê°€ ì ê²Œ ë“¤ë©´ì„œë„ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.

  - ë‹¨, layer, kernel call, activation load/store ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë¯€ë¡œ, memory efficiency ì¸¡ë©´ì—ì„œëŠ” ë” ë¹„íš¨ìœ¨ì ì´ë‹¤. 

    íŠ¹íˆ VGGNetì˜ $(3 \times 3)$ convolutionì€ bottleneckì„ ìœ ë°œí•˜ëŠ” ì§€ì ì´ ë˜ì—ˆë‹¤.

    ![VGGNet bottleneck](images/VGGNet_FLOP_bottleneck.png)

---

### 7.2.2 SqueezeNet

> [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size ë…¼ë¬¸(2016)](https://arxiv.org/pdf/1602.07360)

**SqueezeNet**ì€ $3 \times 3$ convolutionì„ **fire module**ì´ë¼ëŠ” ì—°ì‚°ìœ¼ë¡œ êµì²´í•˜ì—¬, ë” ì ì€ parameterë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì—°ì‚°ì„ êµ¬í˜„í–ˆë‹¤. 

![SqueezeNet](images/SqueezeNet.png)

- head

  **global average pooling**ì„ ì‚¬ìš©í•˜ì—¬ costë¥¼ ì¤„ì¸ë‹¤.

- fire module

  $1 \times 1$ convolution(**squeeze**)ê³¼ $3 \times 3$ convolution(**expand**)ì„ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ íš¨ê³¼ì ìœ¼ë¡œ ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤.

  > [1x1 convolutionì´ë€?](https://euneestella.github.io/research/2021-10-14-why-we-use-1x1-convolution-at-deep-learning/)
  
  > $1 \times 1$ convolutionì„ ì´ìš©í•˜ë©´ resolution ë³€í™” ì—†ì´ input feature mapì˜ \#channelsë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆë‹¤. **pointwise convolution**ì´ë¼ê³ ë„ ì§€ì¹­í•œë‹¤.

fire moduleì˜ ë‹¨ê³„ë³„ ê³¼ì •ì„ ë” ìì„¸íˆ ì‚´í´ë³´ì.

![fire module](images/fire_module_2.png)

- Squeeze

    1x1 convolutionìœ¼ë¡œ channelì„ ì••ì¶•í•œë‹¤.

    ![SqueezeNet 1x1](images/SqueezeNet_1x1_filter.png)

- expand

  1x1 convolution, ì¼ë¶€ëŠ” 3x3 convolution ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤.

- concatenate
  
  1x1 convolution output, 3x3 convolution outputì„ í•©ì¹œë‹¤.

---

### 7.2.3 ResNet50: bottleneck block

> [Deep Residual Learning for Image Recognition ë…¼ë¬¸(2015)](https://arxiv.org/abs/1512.03385)

ResNet50ì—ì„œëŠ” **bottleneck block**ì„ ë„ì…í•œë‹¤.

![ResNet bottleneck block](images/ResNet_bottleneck.png)

1. $1 \times 1$ convolution

    \#channels: $2048 \rightarrow 512$

2. $3 \times 3$ convolution

    > batch normalization, ReLU ì ìš©

3. $1 \times 1$ convolution

    \#channels: $512 \rightarrow 2048$

4. shortcut

    $F(x) + x$ 

### <span style='background-color: #393E46; color: #F7F7F7'>&nbsp;&nbsp;&nbsp;ğŸ“ ì˜ˆì œ 1: bottleneck block MACs &nbsp;&nbsp;&nbsp;</span>

ìœ„ bottleneck block ì˜ˆì‹œì—ì„œ ì–¼ë§ˆë‚˜ \#MACs ì—°ì‚°ì´ ì¤„ì—ˆëŠ”ì§€ë¥¼ êµ¬í•˜ë¼.

### <span style='background-color: #C2B2B2; color: #F7F7F7'>&nbsp;&nbsp;&nbsp;ğŸ” í’€ì´&nbsp;&nbsp;&nbsp;</span>

- ê¸°ì¡´(\#channels 2048, \#kernels 9)

$$ 2048 \times 2048 \times H \times W \times 9 = 512 \times 512 \times H \times W \times 144 $$

- bottleneck block

$$ 2048 \times 512 \times H \times W \times 1 $$

$$ + 512 \times 512 \times H \times W \times 9 $$

$$ + 2048 \times 512 \times H \times W \times 1 $$

$$ = 512 \times 512 \times H \times W \times 17 $$

ì´ 8.5ë°° \#MACs ì—°ì‚°ì´ ì¤„ì–´ë“ ë‹¤.

---

### 7.2.4 ResNeXt: grouped convolution

> [Aggregated Residual Transformations for Deep Neural Networks ë…¼ë¬¸(2017)](https://arxiv.org/abs/1611.05431)

**ResNeXt**(2017)ì—ì„œëŠ” **grouped convolution**ì„ ë„ì…í•œë‹¤. ë‹¤ìŒì€ ê²°ê³¼ëŠ” ë™ì¼í•˜ì§€ë§Œ ê³¼ì •ì€ ë‹¤ë¥¸ ì„¸ ê°€ì§€ ë°©ì‹ì˜ grouped convolution ì˜ˆì‹œë‹¤.

![ResNeXt](images/ResNeXt.png)

- ì™¼ìª½

  - input(dimension 256)ì— $1 \times 1$ convolutionì„ ì ìš©í•˜ì—¬ 128 dimensionìœ¼ë¡œ ì••ì¶•í•œë‹¤.
  
  - 32ê°œ groupìœ¼ë¡œ ë‚˜ëˆ  $3 \times 3$ group convolutionì„ ìˆ˜í–‰í•œë‹¤.

- ì¤‘ê°„

  - input(dimension 256)ì„ 32ê°œ groupìœ¼ë¡œ ë¨¼ì € ë‚˜ëˆˆ ë’¤, $1 \times 1$ convolutionì„ ì ìš©í•˜ì—¬ ê°ê° 4 dimensionìœ¼ë¡œ ì••ì¶•í•œë‹¤.
  
  - $3 \times 3$ group convolutionì„ ìˆ˜í–‰ í›„ concatenationí•œë‹¤.

- ì˜¤ë¥¸ìª½

  - concatenation ëŒ€ì‹  $1 \times 1$ convolutionìœ¼ë¡œ 256 dimensionìœ¼ë¡œ í™•ì¥í•œ ë’¤ í•©ì‚°í•œë‹¤.

ë§¨ ì™¼ìª½ ë°©ì‹ì´ parallel costê°€ ë” ì ê¸° ë•Œë¬¸ì— hardware-friendlyí•˜ê³  GPU ê°€ì†ì— ìœ ë¦¬í•˜ë‹¤.

> ì‚¬ì‹¤ ì¤‘ê°„ì´ ì œì¼ ë¨¼ì € ì œì•ˆëœ ResNeXt blockì´ë‹¤.

---

### 7.2.5 MobileNet: depthwise-separable block

> [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications ë…¼ë¬¸(2017)](https://arxiv.org/abs/1704.04861)

> [depthwise-separable convolution ì •ë¦¬](https://velog.io/@woojinn8/LightWeight-Deep-Learning-5.-MobileNet)

**MobileNet**(2017)ì€ depthwise-separable convolution, pointwise convolution ë‘ ê°€ì§€ layerë¡œ êµ¬ì„±ëœ **depthwise-separable block**ì„ ì œì•ˆí–ˆë‹¤. 

> \#channels = \#groupsì¸ group convolutionì˜ ê·¹ë‹¨ì ì¸ í˜•íƒœë¡œë„ ë³¼ ìˆ˜ ìˆë‹¤.

![depthwise-separable convolution](images/depthwise-separable_3.png)

- **depthwise-seperable convolution**

  inputì˜ ëª¨ë“  channelì„ ë¶„ë¦¬í•˜ê³ , spatial information captureë¥¼ ìœ„í•œ convolutionì„ ìˆ˜í–‰í•œë‹¤.

- **pointwise convolution**

  channelë³„ë¡œ ìˆ˜í–‰ëœ ê²°ê³¼ë¬¼ì„ ë‹¤ì‹œ í•©ì¹œ ë’¤, pointwise convolutionì„ í†µí•´ channel ì‚¬ì´ì˜ informationì„ fuseí•œë‹¤.

ì¶”ê°€ë¡œ activation functionìœ¼ë¡œ ReLU6ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ì‚°ëŸ‰ì„ ë”ìš± ì¤„ì¸ë‹¤.

![ReLU6](images/ReLU6.png)

> depthwise-separable convolutionì€ Xceptionì´ë€ ë…¼ë¬¸ì—ì„œ ë¨¼ì € ì œì•ˆëœ ë°©ì‹ì´ë‹¤. í•˜ì§€ë§Œ Xception ë…¼ë¬¸ì€ accuracy í–¥ìƒì„ ìœ„í•œ ëª©ì ì´ì—ˆì§€ë§Œ MobileNetì€ ê²½ëŸ‰í™”ë¥¼ ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤.

---

#### 7.2.5.1  Width Multiplier, Resolution Multiplier

ë˜í•œ MobileNetì—ì„œëŠ” model shrinkingì„ ìœ„í•œ ë‘ ê°€ì§€ parameterë¥¼ ì¶”ê°€ë¡œ ë„ì…í–ˆë‹¤.

- **Width Multiplier** $\alpha$

  ê° layerê°€ ê°–ëŠ” \#channelsë¥¼ uniformí•˜ê²Œ scalingí•˜ëŠ” parameterì´ë‹¤.
  
  - \#input channels: $M \rightarrow {\alpha}M$
  
  - \#output channels $N \rightarrow {\alpha}N$

  - $\alpha \in (0, 1]$ 

  > ì£¼ë¡œ 1, 0.75, 0.5, 0.25 ê°’ì„ ì‚¬ìš©í•œë‹¤.

- **Resolution Multiplier** $\rho$

  input resolutionì„ ì¤„ì´ëŠ” parameter. ê²°ê³¼ì ìœ¼ë¡œ ëª¨ë“  layerì˜ internal representationì´ ë™ì¼í•œ ë¹„ìœ¨ë¡œ ê°ì†Œí•˜ê²Œ ëœë‹¤.

  - $\rho \in (0, 1]$

---

### 7.2.6 MobileNetV2: inverted bottleneck block

> [MobileNetV2: Inverted Residuals and Linear Bottlenecks ë…¼ë¬¸(2018)](https://arxiv.org/pdf/1801.04381.pdf)

**MobileNetV2**(2018)ëŠ” depthwise-separable blockì˜ ì •ë³´ ì†ì‹¤ì„ compensateí•  ìˆ˜ ìˆëŠ” **inverted bottleneck block** ë°©ë²•ì„ ì œì‹œí•œë‹¤. 

- íŠ¹íˆ ReLUë¥¼ activation functionìœ¼ë¡œ ì‚¬ìš©í•  ë•Œ, input/output channelì´ ë§ì„ìˆ˜ë¡ ì •ë³´ ì†ì‹¤ì´ ì ë‹¤ëŠ” ì ì„ ì´ìš©í•œë‹¤.

  ![channel compensate](images/linear_bottlenecks.png)

  > ë” ë‚®ì€ ì°¨ì›ì˜ subspaceë¡œ mappingë˜ëŠ” informationì„ **maniford**ë¼ê³  ì§€ì¹­í•œë‹¤.

inverted bottleneck blockì—ì„œëŠ” ReLUë¡œ ì¸í•œ ì •ë³´ ì†ì‹¤ì„ ë§‰ê¸° ìœ„í•´, ë¨¼ì € $1 \times 1$ convolutionì„ ì´ìš©í•´ input channel ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤.

![Mb vs MbV2](images/Mb_and_MbV2_block.png)

- MobileNetV2 stride=1 block

  inverted bottleneck blockê³¼ skip connectionì„ ì ìš©í•œë‹¤.

  ![inverted residual block](images/inverted_residual_block.png)

- MobileNetV2 stride=2 block

  inverted bottleneck block ì—°ì‚°ê³¼ downsamplingì„ ìˆ˜í–‰í•œë‹¤.

ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ MobileNetV2ì˜ architectureëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

![MbV2 arch](images/MbV2_arch.png)

- $t$ : expansion factor(ì£¼ë¡œ 5~10)

- $c$ : \#output channels

- $n$ : \#blocks

- $s$ : stride

- spatial convolutionì€ ëª¨ë‘ 3x3 kernelë§Œì„ ì‚¬ìš©í•œë‹¤.

---

### 7.2.7 ShuffleNet: 1x1 group convolution & channel shuffle

> [ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices ë…¼ë¬¸(2018)](https://arxiv.org/abs/1707.01083)
 
ShuffleNetì—ì„œëŠ” ë‹¤ë¥¸ groupì˜ channel informationë¥¼ êµí™˜í•˜ê¸° ìœ„í•œ **channel shuffle** ê¸°ë²•ì„ ì œì•ˆí–ˆë‹¤.

![ShuffleNet](images/ShuffleNet.png)

![channel shuffle](images/channel_shuffle.png)

---

### 7.2.8 SENet: Squeeze-and-Excitation block

> [Squeeze-and-Excitation Networks ë…¼ë¬¸(2017)](https://arxiv.org/pdf/1709.01507.pdf)

SENetì€ **Squeeze-and-Excitation**(**SE**) blockì„ ë„ì…í•˜ì—¬ ILSVRC 2017ì—ì„œ ìš°ìŠ¹í•œ modelì´ë‹¤. 

- SE blockì˜ ëª©ì ì€ feature mapì˜ <U>ê° channelì˜ ì •ë³´ê°€ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ë¥¼ íŒë‹¨</U>í•˜ëŠ” ê²ƒì´ë‹¤. 

SE blockì€ ë‹¤ë¥¸ CNN model(VGG, ResNet ë“±)ì˜ ì–´ë””ë“  ë¶€ì°©í•  ìˆ˜ ìˆë‹¤. blockì€ í¬ê²Œ squeeze, excitation ë‹¨ê³„ë¡œ ë‚˜ë‰œë‹¤.

![SE block](images/SE_block.png)

- **Squeeze**(ì••ì¶•)

  spatial informationì„ $1 \times 1$ ë¡œ ì••ì¶•(depthì¸ channel ê°œìˆ˜ëŠ” ìœ ì§€). global average pooling ì—°ì‚°ì„ ì´ìš©í•œë‹¤.

  - $F_{sq}(\cdot)$ : Squeeze(global average pooling)

  - $u_{c}$ : channel $c$ ì˜ feature map( $H \times W$ )

$$ z = F_{sq}(u_{c}) = {{1} \over {H \times W}} {\sum_{i=1}^{H}}{\sum_{j=1}^{W}}{u_{c}(i, j)} $$

- **Excitation**(ì¬ì¡°ì •)

  squeezeë¡œ ì–»ì€ 1ì°¨ì› ë²¡í„°ë¥¼ normalizeí•œ ë’¤ ê°€ì¤‘ì¹˜ ë²¡í„°ë¡œ ì‚¬ìš©í•œë‹¤. 
  
  normalizeëŠ” FC1 - ReLU - FC2 - Sigmoid ìˆœì„œë¡œ ì§„í–‰ëœë‹¤.

  - $W_{1}, W_{2}$ : FC layer weight matrix

    - reduction ratio $r$ ì„ ë‘¬ì„œ ë…¸ë“œ ìˆ˜ë¥¼ ì¡°ì ˆí•œë‹¤.

    - $W_{1} \in \mathbb{R}^{{C \over r} \times C}$ , $W_{2} \in \mathbb{R}^{C \times {C \over r}}$

  - sigmoid functionì„ ì´ìš©í•´ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ normalizeí•œë‹¤.

  ![Excitation](images/Excitation.png)

$$ s = F_{ex}(z, W) = {\sigma}(W_{2} {\delta}(W_{1} z)) $$

> $\delta$ : ReLU ì—°ì‚°, $\sigma$ : Sigmoid ì—°ì‚°

> reduction ratio $r$ ì€ \#parameters(ê³„ì‚° ë³µì¡ë„)ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤. ë”°ë¼ì„œ $r$ ì„ ë°”ê¿”ê°€ë©° ìµœì ì˜ ê°’ì„ ì°¾ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.(ë¬¼ë¡  SE blockì„ ì¶”ê°€í•´ì„œ \#parametersê°€ í¬ê²Œ ëŠ˜ì–´ë‚˜ì§€ëŠ” ì•ŠëŠ”ë‹¤.)

ì´ë ‡ê²Œ êµ¬í•œ ê°€ì¤‘ì¹˜ ë²¡í„° $s$ ë¥¼ ì›ë˜ feature map $u$ ì— ê³±í•´ì„œ ì¤‘ìš”í•œ channel ì •ë³´ë¥¼ ê°•ì¡°í•œë‹¤.

$$ F_{scale}(u_{c}, s_{c}) = s_{c} \cdot u_{c} $$


---

### 7.2.9 MobileNetV3

> [Searching for MobileNetV3 ë…¼ë¬¸(2019)](https://arxiv.org/pdf/1905.02244.pdf)

**MobileNetV3**(2019)ëŠ” MobileNetV2ì˜ í›„ì† ë…¼ë¬¸ìœ¼ë¡œ, NetAdapt algorithm + hardware-aware NASë¥¼ ì´ìš©í•´ ì°¾ì€ ê°œì„ ëœ architectureì´ë‹¤. ë…¼ë¬¸ì—ì„œëŠ” model sizeê°€ ë‹¤ë¥¸ ë‘ ê°€ì§€ ë²„ì „ì„ ì œì•ˆí•œë‹¤.

- MobileNetV3-Large

  ![MbV3-Large](images/MbV3-Large.png)

- MobileNetV3-Small

  ![MbV3-Small](images/MbV3-Small.png)

ì•ì„œ ë³¸ MobileNetV2ì™€ ë¹„êµí•˜ë©´ ë” ë§ì€ layerë¥¼ ê°€ì§€ë©´ì„œë„ ë‹¤ì–‘í•œ kernel sizeë¥¼ ì‚¬ìš©í•œë‹¤. 

- SE: Squeeze-and-Excitation block

- NL: type of nonlinearity used

  - HS: h-swish

  - RE: ReLU

- NBN: batch normalization

---

#### 7.2.9.1 MobileNetV2 vs MobileNetV3

íŠ¹íˆ MbV2ì˜ expensive layersì™€ nonlinearity functionì„ ë³´ì™„í•œ êµ¬ì¡°ë¥¼ ê°–ê³  ìˆë‹¤.

- redesign expensive layers(last stage)

  ![MbV3 last stage](images/MbV3_last_stage.png)

  - Original Last Stage(MobileNetV2)

    1x1 convë¥¼ ì‚¬ìš©í•´ featureë¥¼ 7x7x1280ìœ¼ë¡œ ë§Œë“  ë’¤ avgpoolì„ ì ìš©í–ˆë‹¤. 
    
    ë•ë¶„ì— rich featureë¥¼ ì–»ì„ ìˆ˜ëŠ” ìˆì—ˆì§€ë§Œ costê°€ ë‹¤ë¥¸ layerì— ë¹„í•´ì„œ ë„ˆë¬´ ì»¸ë‹¤.

  - Efficient Last Stage(MobileNetV3)

    ë¨¼ì € avgpoolì„ ì ìš©í•´ì„œ featureë¥¼ ì¶”ì¶œí•œ ë’¤ 1x1 convë¥¼ í†µí•´ channel ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤. 

- nonlinearity(activation function)ìœ¼ë¡œ **h-swish**ë¥¼ í•¨ê»˜ ì‚¬ìš©í•œë‹¤.

  > ë‹¨ë…ìœ¼ë¡œ h-swishë§Œì„ ì‚¬ìš©í•˜ê¸°ë³´ë‹¤ëŠ” ReLUì™€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” í¸ì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

---

#### 7.2.9.2 swish, h-swish

ìš°ì„  ReLUë¥¼ ëŒ€ì²´í•˜ê¸° ìœ„í•œ nonlinearityì¸ **swish**ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¥¼ ê°–ëŠ”ë‹¤.

![swish vs ReLU](images/swish_vs_ReLU.png)

$$ \mathrm{swish} \, x = x \cdot {\sigma}(x) $$

$$ {\sigma}(x) = {{1} \over {1 + e^{-x}}} $$

- sigmoid function( ${\sigma}(x)$ )ì„ ì‚¬ìš©í•œë‹¤.

- í•˜ì§€ë§Œ ReLUì™€ ë‹¬ë¦¬ ì–´ëŠ ì •ë„ ìŒìˆ˜ë¥¼ í—ˆìš©í•˜ë©° ì§ì„ ì´ ì•„ë‹Œ ê³¡ì„  í˜•íƒœë¥¼ ê°–ëŠ”ë‹¤.

- ë¯¸ë¶„í•´ì„œ ìƒìˆ˜ ê°’ì´ ì•„ë‹ˆë‹¤.

í•˜ì§€ë§Œ sigmoid ì—°ì‚°ì€ ë³µì¡í•œ ì—°ì‚°ì´ë©° hardwareì— ë”°ë¼ ì œì•½ì´ ìˆê¸° ë•Œë¬¸ì— ì´ë¥¼ ë³´ì™„í•˜ëŠ” **h-swish**ê°€ ë“±ì¥í–ˆë‹¤.

![swish vs h-swish](images/swish_vs_h-swish.png)

$$ x{{\mathrm{ReLU}6(x+3)} \over {6}} $$

---

### 7.2.10 accuracy-efficiency trade-off on ImageNet

ë‹¤ìŒì€ ImageNet ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨í•œ ì—¬ëŸ¬ modelì˜ MACsì™€ accuracyë¥¼ ë‚˜íƒ€ë‚¸ ë„í‘œë‹¤.

![accuracy-efficiency tradeoff on ImageNet](images/accuracy-efficiency_tradeoff.png)

> ë‹¨, ì‹¤ì œ downstream(ì‚°ì—…)ì—ì„œ í™œìš©í•  ë•ŒëŠ” benchmarkë§Œ ë¯¿ì–´ì„œëŠ” ì•ˆ ëœë‹¤. ì„±ëŠ¥ì´ benchmarkì™€ ì¼ì¹˜í•œë‹¤ëŠ” ë³´ì¥ì€ ì—†ë‹¤.

---