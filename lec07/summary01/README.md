# 7 Neural Architecture Search (Part I)

> [Lecture 07 - Neural Architecture Search (Part I) | MIT 6.S965](https://www.youtube.com/watch?v=NQj5TkqX48Q)

> [AutoML ê¸°ìˆ  ë™í–¥](https://ettrends.etri.re.kr/ettrends/178/0905178004/34-4_32-42.pdf2)

AutoML(ìë™ê¸°ê³„í•™ìŠµ)ì—ì„œëŠ” í¬ê²Œ ì„¸ ê°€ì§€ processë¥¼ ìë™í™”í•˜ëŠ” ë° ì¤‘ì ì„ ë‘”ë‹¤.

![AutoML](images/autoML.png)

- **feature engineering**

    domain knowledgeë¥¼ ë°”íƒ•ìœ¼ë¡œ featureë¥¼ ë‹¤ë“¬ëŠ” ê³¼ì •ì´ë‹¤.

- **Hyper-Parameter Optimization**(HPO)

    **meta-optimization**ìœ¼ë¡œ, hyperparameter ìì²´ë¥¼ ìë™ìœ¼ë¡œ optimizationí•œë‹¤.

    > hyperparameter: learning rate, lr scheduling, loss function, epoch, weight initialization, normalization, \#layers ë“±

- **Neural Architecture Search**(NAS)

  ìµœì  model architectureë¥¼ ìë™ìœ¼ë¡œ íƒìƒ‰í•œë‹¤.


ì´ì¤‘ì—ì„œë„ Neural Architecture Search(NAS)ë¥¼ ì¤‘ì ì ìœ¼ë¡œ ì‚´í´ë³¼ ê²ƒì´ë‹¤.

---

## 7.1 Basic Concepts

---

### 7.1.1 Stages

Network ArchitectureëŠ” input stem, head, ê·¸ë¦¬ê³  ì—¬ëŸ¬ stageë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.

> stageë¥¼ ì „ì› ë¬¶ì–´ì„œ bodyë¡œ í‘œí˜„í•˜ëŠ” ê²½ìš°ë„ ìˆë‹¤. stageëŠ” ì£¼ë¡œ NASì—ì„œ ë§ì´ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì´ë‹¤.

![input stem, head, stages](images/stage.png)

- **Input Stem** 

  ê°€ì¥ í° resolution inputì„ ê°–ëŠ” ë¶€ë¶„ìœ¼ë¡œ, aggressiveí•˜ê²Œ **downsampling**ì„ ìˆ˜í–‰í•œë‹¤.

  - í° receptive fieldë¥¼ ì–»ê¸° ìœ„í•´, ëŒ€ì²´ë¡œ large kernel( $7 \times 7$ )ì„ ì‚¬ìš©í•œë‹¤.

  - <U>channel ìˆ˜ê°€ 3ê°œë¡œ ë§¤ìš° ì ê¸° ë•Œë¬¸ì—, ê³„ì‚°ëŸ‰ ìì²´ê°€ ë§ì´ í•„ìš”í•˜ì§€ëŠ” ì•Šë‹¤.</U>

- **Stage**

  ê° stage ë‚´ë¶€ì—ì„œëŠ” input resolutionì´ ë™ì¼í•˜ë‹¤.

  - early stage: large feature map sizeë¥¼ ê°–ëŠ”ë‹¤.(activation memoryê°€ ë§ì´ í•„ìš”í•˜ë‹¤.)

  - late stage: small feature map sizeë¥¼ ê°–ëŠ”ë‹¤.

    ëŒ€ì‹  ë§ì€ width(\#channels)ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆë‹¤.(weightsë¥¼ ìœ„í•œ memoryê°€ ë§ì´ í•„ìš”í•˜ë‹¤.)

- **head**

  **application-specific**í•˜ë©°, detection head, segmentation head ë“±ì´ ìœ„ì¹˜í•˜ê²Œ ëœë‹¤.

---

### 7.1.2 Downsampling, Residual/Skip connection

![downsample](images/downsample.png)

- ì£¼ë¡œ ê° stageë³„ first blockì—ì„œ **feature map downsampling**ì„ ìˆ˜í–‰í•œë‹¤. 

  stride convolution í˜¹ì€ poolingì„ í†µí•´ downsamplingì„ ìˆ˜í–‰í•œë‹¤.

- ë‚˜ë¨¸ì§€ blocksì—ì„œëŠ” input, output dimensionsì´ ë™ì¼í•˜ë¯€ë¡œ **residual/skip connection**ì„ ë”í•´ì¤„ ìˆ˜ ìˆë‹¤.

---

## 7.2 manually-designed neural network

---

### 7.2.1 AlexNet, VGGNet

> [AlexNet ë…¼ë¬¸(2012)](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)

> [VGGNet ë…¼ë¬¸(2014)](https://arxiv.org/abs/1409.1556)

- **AlexNet**

  ![AlexNet](https://github.com/erectbranch/TinyML_and_Efficient_DLC/blob/master/lec07/summary01/images/AlexNet_arch.png)

  ealry stageì—ì„œ í° kernelì„ ì‚¬ìš©í•˜ëŠ” íŠ¹ì§•ì„ ê°€ì¡Œë‹¤.
  
  - $11 \times 11$ (channel 96) , ê·¸ ë‹¤ìŒì€ $5 \times 5$ (channel 256)

- **VGGNet**

  ë°˜ë©´ <U>early stageì—ì„œ ì‘ì€ kernelì„ ì—¬ëŸ¬ ê°œ ìŒ“ì•„ì„œ</U> ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì–»ì—ˆë‹¤.

  ![VGGNet](https://github.com/erectbranch/TinyML_and_Efficient_DLC/blob/master/lec07/summary01/images/VGGNet_arch.png)

  - ì˜¤ë¡œì§€ $3 \times 3$ convolutionì„ ì‚¬ìš©í•œë‹¤. 
  
  - í•œ stageì—ì„œ $3 \times 3$ ë ˆì´ì–´ë¥¼ ë‘ ê°œ ìŒ“ëŠ” ê²ƒì´( $3 \times 3 + 3 \times 3 = 18$ parameters ),  $5 \times 5$ (=25 parameters) ë ˆì´ì–´ í•˜ë‚˜ë³´ë‹¤ computational costê°€ ì ê²Œ ë“¤ë©´ì„œë„ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.

  - ë‹¨, layer, kernel call, activation load/store ìˆ˜ ì¦ê°€ë¡œ, memory efficiency ì¸¡ë©´ì—ì„œëŠ” ë” ë¹„íš¨ìœ¨ì ì´ë‹¤. 

    íŠ¹íˆ VGGNetì˜ $(3 \times 3)$ convolutionì€ bottleneckì„ ìœ ë°œí•˜ëŠ” ì§€ì ì´ ë˜ì—ˆë‹¤.

    ![VGGNet bottleneck](https://github.com/erectbranch/TinyML_and_Efficient_DLC/blob/master/lec07/summary01/images/VGGNet_FLOP_bottleneck.png)

---

### 7.2.2 SqueezeNet: file module

> [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size ë…¼ë¬¸(2016)](https://arxiv.org/pdf/1602.07360)

> [1x1 convolutionì´ë€?](https://euneestella.github.io/research/2021-10-14-why-we-use-1x1-convolution-at-deep-learning/)

**SqueezeNet**ì€ $3 \times 3$ convolutionì„ **fire module**ë¡œ ëŒ€ì²´í•˜ì—¬, ë” ì ì€ \#parametersë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤. ë‹¤ìŒì€ SqueezeNetì˜ architectureë¥¼ ë¬˜ì‚¬í•œ ê·¸ë¦¼ì´ë‹¤.

![SqueezeNet](images/SqueezeNet.png)

- head

  **global average pooling**ì„ ì‚¬ìš©.

- fire module

  $1 \times 1$ convolution(**squeeze**), $3 \times 3$ convolution(**expand**)ì„ ì‚¬ìš©.

fire moduleì„ ì„¸ë¶€ì ìœ¼ë¡œ ìì„¸íˆ ì‚´í´ë³´ì.

![fire module](images/fire_module_2.png)

- Squeeze

  1x1 convolutionìœ¼ë¡œ channelì„ ì••ì¶•í•œë‹¤.

- expand

  ê°ì ì—°ì‚°ì„ ìˆ˜í–‰í•˜ë©°, ë‹¤ì‹œ channelì„ í™•ì¥í•œë‹¤.

  - 1x1 convolution
  
  - 3x3 convolution

- concatenate
  
  1x1, 3x3 convolution outputì„ í•©ì¹œë‹¤.

---

### 7.2.3 ResNet50: bottleneck block

> [Deep Residual Learning for Image Recognition ë…¼ë¬¸(2015)](https://arxiv.org/abs/1512.03385)

ResNet50ì—ì„œëŠ” **bottleneck block**ì„ ë„ì…í•œë‹¤. 1x1 convolutionì„ ì‚¬ìš©í•´ ì—°ì‚°ëŸ‰ì€ ì¤„ì´ë©´ì„œ, residual connectionì„ ë„ì…í•´ì„œ gradient vanishing ë¬¸ì œë¥¼ í•´ê²°í–ˆë‹¤. ResNet ì´ë˜ë¡œ CNNì„ ë” ê¹Šê²Œ ìŒ“ì„ ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.

![ResNet bottleneck block](images/ResNet_bottleneck.png)

1. $1 \times 1$ convolution

2. $3 \times 3$ convolution

    ì´ë•Œ batch normalization, ReLUë¥¼ ì ìš©í•œë‹¤.

3. $1 \times 1$ convolution

4. shortcut

    $F(x) + x$ 

### <span style='background-color: #393E46; color: #F7F7F7'>&nbsp;&nbsp;&nbsp;ğŸ“ ì˜ˆì œ 1: bottleneck block MACs &nbsp;&nbsp;&nbsp;</span>

ìœ„ bottleneck block ê·¸ë¦¼ì—ì„œ \#MACs ì—°ì‚°ì´ ì–¼ë§ˆë‚˜ ì¤„ì—ˆëŠ”ì§€ ê³„ì‚°í•˜ë¼.

### <span style='background-color: #C2B2B2; color: #F7F7F7'>&nbsp;&nbsp;&nbsp;ğŸ” í’€ì´&nbsp;&nbsp;&nbsp;</span>

- full convolution(\#channels 2048, \#kernels 9)

$$ 2048 \times 2048 \times H \times W \times 9 = 512 \times 512 \times H \times W \times 144 $$

- bottleneck block

$$ 2048 \times 512 \times H \times W \times 1 $$

$$ + 512 \times 512 \times H \times W \times 9 $$

$$ + 2048 \times 512 \times H \times W \times 1 $$

$$ = 512 \times 512 \times H \times W \times 17 $$

ì´ **8.5ë°°** \#MACs ì—°ì‚°ì´ ì¤„ì–´ë“¤ì—ˆë‹¤.

---

### 7.2.4 ResNeXt: grouped convolution

> [Aggregated Residual Transformations for Deep Neural Networks ë…¼ë¬¸(2017)](https://arxiv.org/abs/1611.05431)

**ResNeXt**(2017)ì—ì„œëŠ” **grouped convolution**ì„ ë„ì…í•œë‹¤. \#parameters ìˆ˜ë¥¼ êµ‰ì¥íˆ ì¤„ì´ë©´ì„œë„, ì •í™•ë„ëŠ” ê±°ì˜ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.

grouped convolutionì— ìˆì–´ì„œ, ì–´ë–»ê²Œ groupì„ êµ¬ì„±í•˜ëŠ”ê°€ì— ë”°ë¼ì„œë„ íš¨ìœ¨ì´ ë‹¬ë¼ì§„ë‹¤. ë‹¤ìŒì€ ê²°ê³¼ëŠ” ë™ì¼í•˜ì§€ë§Œ ê³¼ì •ì€ ë‹¤ë¥¸ ì„¸ ê°€ì§€ ë°©ì‹ì˜ grouped convolution ì˜ˆì‹œë‹¤.

![ResNeXt](images/ResNeXt.png)

- ì™¼ìª½

  - input(dimension 256)ì— $1 \times 1$ convolutionì„ ì ìš©í•˜ì—¬ 128 dimensionìœ¼ë¡œ ì••ì¶•í•œë‹¤.
  
  - 32ê°œ groupìœ¼ë¡œ ë‚˜ëˆ  $3 \times 3$ group convolutionì„ ìˆ˜í–‰í•œë‹¤.

- ì¤‘ê°„

  - input(dimension 256)ì„ 32ê°œ groupìœ¼ë¡œ ë¨¼ì € ë‚˜ëˆˆ ë’¤, $1 \times 1$ convolutionì„ ì ìš©í•˜ì—¬ ê°ê° 4 dimensionìœ¼ë¡œ ì••ì¶•í•œë‹¤.
  
  - $3 \times 3$ group convolutionì„ ìˆ˜í–‰ í›„ concatenationí•œë‹¤.

- ì˜¤ë¥¸ìª½

  - concatenation ëŒ€ì‹  $1 \times 1$ convolutionìœ¼ë¡œ 256 dimensionìœ¼ë¡œ í™•ì¥í•œ ë’¤ í•©ì‚°í•œë‹¤.

ì´ì¤‘ì—ì„œë„ ë§¨ ì™¼ìª½ ë°©ì‹ì´ parallel costê°€ ë” ì ê¸° ë•Œë¬¸ì—, hardware-friendlyí•˜ê³  GPU ê°€ì†ì— ìœ ë¦¬í•˜ë‹¤.

> ì¤‘ê°„ ê·¸ë¦¼ì´ ì œì¼ ë¨¼ì € ì œì•ˆëœ ResNeXt blockì´ë‹¤.

---

### 7.2.5 MobileNet: depthwise-separable block

> [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications ë…¼ë¬¸(2017)](https://arxiv.org/abs/1704.04861)

**MobileNetV1**(2017)ì€ depthwise-separable convolution, pointwise convolution ë‘ ê°€ì§€ layerë¡œ êµ¬ì„±ëœ **depthwise-separable block**ì„ ì œì•ˆí–ˆë‹¤.

- ì…ë ¥ë¶€ í•˜ë‚˜ì˜ full convolutionì„ ì œì™¸í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ depthwise-separable convolutionìœ¼ë¡œ êµ¬ì„±ëœë‹¤.

> depthwise-separable block: \#channels = \#groupsì¸ ê·¹ë‹¨ì ì¸ í˜•íƒœì˜ group convolutionë¡œë„ ë³¼ ìˆ˜ ìˆë‹¤.

> depthwise-separable convolutionì€ Xceptionì´ë€ ë…¼ë¬¸ì—ì„œ ë¨¼ì € ì œì•ˆëœ ë°©ì‹ì´ë‹¤. í•˜ì§€ë§Œ Xception ë…¼ë¬¸ì€ accuracy í–¥ìƒì„ ìœ„í•œ ëª©ì ì´ì—ˆì§€ë§Œ MobileNetì€ ê²½ëŸ‰í™”ë¥¼ ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤.

![depthwise-separable convolution](images/depthwise-separable_3.png)

- **depthwise convolution**

  inputì˜ ëª¨ë“  channelì„ ë¶„ë¦¬í•˜ê³ , channelë§ˆë‹¤ spatial information captureë¥¼ ìœ„í•œ convolutionì„ ìˆ˜í–‰í•œë‹¤.

- **pointwise convolution**

  channelë³„ë¡œ ìˆ˜í–‰ëœ ê²°ê³¼ë¬¼ì„ ë‹¤ì‹œ í•©ì¹œ ë’¤, pointwise convolutionì„ í†µí•´ channel ì‚¬ì´ì˜ informationì„ fuseí•œë‹¤.

depthwise convolution ì´í›„ì™€, pointwise convolution ì´í›„ì—, activation functionìœ¼ë¡œ ReLU6ë¥¼ ì‚¬ìš©í•œë‹¤.(ReLUì˜ íŠ¹ì„±ìƒ ì—°ì‚° íš¨ìœ¨ì ì´ë‹¤.)

![ReLU6](images/ReLU6.png)

ì‹¤ì œ ê²°ê³¼ë¥¼ ë³´ë©´ ëª¨ë‘ convolution ì—°ì‚°ìœ¼ë¡œ ì±„ìš´ ëª¨ë¸ë³´ë‹¤ë„, í›¨ì”¬ ì ì€ \#parametersì— ê±°ì˜ ìœ ì‚¬í•œ ì •í™•ë„ë¥¼ ë³´ì¸ë‹¤.

![depthwise-separable vs full convolution](images/depthwise-separable_vs_conv.png)

---

#### 7.2.5.1  Width Multiplier, Resolution Multiplier

MobileNetì—ì„œëŠ” ì¶”ê°€ë¡œ model shrinkingì„ ìœ„í•œ ë‘ ê°€ì§€ hyperparameterë¥¼ ë„ì…í–ˆë‹¤.

- **Width Multiplier** $\alpha$

  \#output channelsì— uniformí•˜ê²Œ ì ìš©ë˜ëŠ” scaling parameter
  
  - \#input channels: $M \rightarrow {\alpha}M$
  
  - \#output channels $N \rightarrow {\alpha}N$

  - $\alpha \in (0, 1]$ 

  > ì£¼ë¡œ 1, 0.75, 0.5, 0.25 ê°’ ì¤‘ì—ì„œ ì‚¬ìš©í•œë‹¤.(1: default MobileNet)

- **Resolution Multiplier** $\rho$

  input resolutionì„ ì¤„ì´ëŠ” parameter. (ê²°ê³¼ì ìœ¼ë¡œ ëª¨ë“  layerì˜ internal representationì´ ë™ì¼í•œ ë¹„ìœ¨ë¡œ ê°ì†Œí•˜ê²Œ ëœë‹¤.)

  - $\rho \in (0, 1]$

---

### 7.2.6 ShuffleNet: 1x1 group convolution & channel shuffle

> [ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices ë…¼ë¬¸(2018)](https://arxiv.org/abs/1707.01083)
 
ShuffleNetì—ì„œëŠ” channel informationì˜ ì†ì‹¤ì„ ë³´ì™„í•˜ê¸° ìœ„í•œ **channel shuffle** ê¸°ë²•ì„ ì œì•ˆí–ˆë‹¤.

![ShuffleNet](images/ShuffleNet.png)

![channel shuffle](images/channel_shuffle.png)

---

### 7.2.7 MobileNetV2: inverted bottleneck block

> [MobileNetV2: Inverted Residuals and Linear Bottlenecks ë…¼ë¬¸(2018)](https://arxiv.org/pdf/1801.04381.pdf)

**MobileNetV2**(2018)ëŠ” depthwise-separable blockì—ì„œì˜ ì •ë³´ ì†ì‹¤ì„ compensateí•  ìˆ˜ ìˆëŠ” **inverted bottleneck block** ë°©ë²•ì„ ì œì‹œí•œë‹¤. 

![inverted residual block](images/inverted_residual_block.png)

- íŠ¹íˆ ReLUëŠ” input/output channelì´ ë§ì„ìˆ˜ë¡ ì •ë³´ ì†ì‹¤ì´ ì ë‹¤ëŠ” ì ì—ì„œ, 1x1 convolutionì„ í™œìš©í•´ ì±„ë„ ìˆ˜ë¥¼ ëŠ˜ë ¤ ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤.

  ![channel compensate](images/linear_bottlenecks.png)

- MobileNetV1ê³¼ ë¹„êµí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì°¨ì´ê°€ ìˆë‹¤.

  ![Mb vs MbV2](images/Mb_and_MbV2_block.png)

  - MobileNetV2 stride=1 block

    inverted bottleneck block + residual connection

  - MobileNetV2 stride=2 block

    inverted bottleneck block + downsampling

ì°¸ê³ ë¡œ MobileNetV2 architectureëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. MobileNetV2 ê¸°ë°˜ì˜ ì•„í‚¤í…ì²˜ëŠ” ì´ì™€ í•˜ì´í¼íŒ¨ëŸ¬ë¯¸í„°ë¥¼ ê°–ëŠ”ë‹¤.

![MbV2 arch](images/MbV2_arch.png)

- $t$ : expansion factor(ì£¼ë¡œ 5~10)

- $c$ : \#output channels

- $n$ : \#blocks

- $s$ : stride

- spatial convolutionìœ¼ë¡œ ëª¨ë‘ 3x3 kernelë§Œì„ ì‚¬ìš©í•œë‹¤.

ì‹¤ì œ MobileNetV1ê³¼ ë¹„êµí–ˆì„ ë•Œ, ë” ì ì€ \#Parametersë¡œ ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ê°–ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

![MbV2 vs MbV1](images/mobilenetv1_vs_shufflenet_vs_mobilenetv2.png)

---

### 7.2.8 SENet: Squeeze-and-Excitation block

> [Squeeze-and-Excitation Networks ë…¼ë¬¸(2017)](https://arxiv.org/pdf/1709.01507.pdf)

SENetì€ **Squeeze-and-Excitation**(**SE**) blockì„ ë„ì…í•˜ì—¬ ILSVRC 2017ì—ì„œ ìš°ìŠ¹í•œ modelì´ë‹¤. 

- SE blockì˜ ëª©ì ì€ feature mapì˜ <U>ê° channelì˜ ì •ë³´ê°€ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ë¥¼ íŒë‹¨</U>í•˜ëŠ” ê²ƒì´ë‹¤. 

SE blockì€ ë‹¤ë¥¸ CNN model(VGG, ResNet ë“±)ì˜ ì–´ë””ë“  ë¶€ì°©í•  ìˆ˜ ìˆë‹¤. blockì€ í¬ê²Œ squeeze, excitation ë‹¨ê³„ë¡œ ë‚˜ë‰œë‹¤.

![SE block](images/SE_block.png)

- **Squeeze**(ì••ì¶•)

  spatial informationì„ $1 \times 1$ ë¡œ ì••ì¶•(depthì¸ channel ê°œìˆ˜ëŠ” ìœ ì§€). global average pooling ì—°ì‚°ì„ ì´ìš©í•œë‹¤.

  - $F_{sq}(\cdot)$ : Squeeze(global average pooling)

  - $u_{c}$ : channel $c$ ì˜ feature map( $H \times W$ )

$$ z = F_{sq}(u_{c}) = {{1} \over {H \times W}} {\sum_{i=1}^{H}}{\sum_{j=1}^{W}}{u_{c}(i, j)} $$

- **Excitation**(ì¬ì¡°ì •)

  squeezeë¡œ ì–»ì€ 1ì°¨ì› ë²¡í„°ë¥¼ normalizeí•œ ë’¤ ê°€ì¤‘ì¹˜ ë²¡í„°ë¡œ ì‚¬ìš©í•œë‹¤. 
  
  normalizeëŠ” FC1 - ReLU - FC2 - Sigmoid ìˆœì„œë¡œ ì§„í–‰ëœë‹¤.

  - $W_{1}, W_{2}$ : FC layer weight matrix

    - reduction ratio $r$ ì„ ë‘¬ì„œ ë…¸ë“œ ìˆ˜ë¥¼ ì¡°ì ˆí•œë‹¤.

    - $W_{1} \in \mathbb{R}^{{C \over r} \times C}$ , $W_{2} \in \mathbb{R}^{C \times {C \over r}}$

  - sigmoid functionì„ ì´ìš©í•´ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ normalizeí•œë‹¤.

  ![Excitation](https://github.com/erectbranch/TinyML_and_Efficient_DLC/blob/master/lec07/summary01/images/Excitation.png)

$$ s = F_{ex}(z, W) = {\sigma}(W_{2} {\delta}(W_{1} z)) $$

> $\delta$ : ReLU ì—°ì‚°, $\sigma$ : Sigmoid ì—°ì‚°

> reduction ratio $r$ ì€ \#parameters(ê³„ì‚° ë³µì¡ë„)ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤. ë”°ë¼ì„œ $r$ ì„ ë°”ê¿”ê°€ë©° ìµœì ì˜ ê°’ì„ ì°¾ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.(ë¬¼ë¡  SE blockì„ ì¶”ê°€í•´ì„œ \#parametersê°€ í¬ê²Œ ëŠ˜ì–´ë‚˜ì§€ëŠ” ì•ŠëŠ”ë‹¤.)

ì´ë ‡ê²Œ êµ¬í•œ ê°€ì¤‘ì¹˜ ë²¡í„° $s$ ë¥¼ ì›ë˜ feature map $u$ ì— ê³±í•´ì„œ ì¤‘ìš”í•œ channel ì •ë³´ë¥¼ ê°•ì¡°í•œë‹¤.

$$ F_{scale}(u_{c}, s_{c}) = s_{c} \cdot u_{c} $$


---

### 7.2.9 MobileNetV3

> [Searching for MobileNetV3 ë…¼ë¬¸(2019)](https://arxiv.org/pdf/1905.02244.pdf)

**MobileNetV3**(2019)ëŠ” MobileNetV2ì˜ í›„ì† ë…¼ë¬¸ìœ¼ë¡œ, NetAdapt algorithm + hardware-aware NASë¥¼ ì´ìš©í•´ ì°¾ì€ ê°œì„ ëœ architectureì´ë‹¤. ë…¼ë¬¸ì—ì„œëŠ” model sizeê°€ ë‹¤ë¥¸ ë‘ ê°€ì§€ ë²„ì „ì„ ì œì•ˆí•œë‹¤.

- MobileNetV3-Large

  ![MbV3-Large](images/MbV3-Large.png)

- MobileNetV3-Small

  ![MbV3-Small](images/MbV3-Small.png)

ì•ì„œ ë³¸ MobileNetV2ì™€ ë¹„êµí•˜ë©´ ë” ë§ì€ layerë¥¼ ê°€ì§€ë©´ì„œë„ ë‹¤ì–‘í•œ kernel sizeë¥¼ ì‚¬ìš©í•œë‹¤. 

- SE: Squeeze-and-Excitation block

- NL: type of nonlinearity used

  - HS: h-swish

  - RE: ReLU

- NBN: batch normalization

---

#### 7.2.9.1 MobileNetV2 vs MobileNetV3

íŠ¹íˆ MbV2ì˜ expensive layersì™€ nonlinearity functionì„ ë³´ì™„í•œ êµ¬ì¡°ë¥¼ ê°–ê³  ìˆë‹¤.

- redesign expensive layers(last stage)

  ![MbV3 last stage](images/MbV3_last_stage.png)

  - Original Last Stage(MobileNetV2)

    1x1 convë¥¼ ì‚¬ìš©í•´ featureë¥¼ 7x7x1280ìœ¼ë¡œ ë§Œë“  ë’¤ avgpoolì„ ì ìš©í–ˆë‹¤. 
    
    ë•ë¶„ì— rich featureë¥¼ ì–»ì„ ìˆ˜ëŠ” ìˆì—ˆì§€ë§Œ costê°€ ë‹¤ë¥¸ layerì— ë¹„í•´ì„œ ë„ˆë¬´ ì»¸ë‹¤.

  - Efficient Last Stage(MobileNetV3)

    ë¨¼ì € avgpoolì„ ì ìš©í•´ì„œ featureë¥¼ ì¶”ì¶œí•œ ë’¤ 1x1 convë¥¼ í†µí•´ channel ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤. 

- nonlinearity(activation function)ìœ¼ë¡œ **h-swish**ë¥¼ í•¨ê»˜ ì‚¬ìš©í•œë‹¤.

  > ë‹¨ë…ìœ¼ë¡œ h-swishë§Œì„ ì‚¬ìš©í•˜ê¸°ë³´ë‹¤ëŠ” ReLUì™€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” í¸ì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

---

#### 7.2.9.2 swish, h-swish

ìš°ì„  ReLUë¥¼ ëŒ€ì²´í•˜ê¸° ìœ„í•œ nonlinearityì¸ **swish**ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¥¼ ê°–ëŠ”ë‹¤.

![swish vs ReLU](images/swish_vs_ReLU.png)

$$ \mathrm{swish} \, x = x \cdot {\sigma}(x) $$

$$ {\sigma}(x) = {{1} \over {1 + e^{-x}}} $$

- sigmoid function( ${\sigma}(x)$ )ì„ ì‚¬ìš©í•œë‹¤.

- í•˜ì§€ë§Œ ReLUì™€ ë‹¬ë¦¬ ì–´ëŠ ì •ë„ ìŒìˆ˜ë¥¼ í—ˆìš©í•˜ë©° ì§ì„ ì´ ì•„ë‹Œ ê³¡ì„  í˜•íƒœë¥¼ ê°–ëŠ”ë‹¤.

- ë¯¸ë¶„í•´ì„œ ìƒìˆ˜ ê°’ì´ ì•„ë‹ˆë‹¤.

í•˜ì§€ë§Œ sigmoid ì—°ì‚°ì€ ë³µì¡í•œ ì—°ì‚°ì´ë©° hardwareì— ë”°ë¼ ì œì•½ì´ ìˆê¸° ë•Œë¬¸ì— ì´ë¥¼ ë³´ì™„í•˜ëŠ” **h-swish**ê°€ ë“±ì¥í–ˆë‹¤.

![swish vs h-swish](images/swish_vs_h-swish.png)

$$ x{{\mathrm{ReLU}6(x+3)} \over {6}} $$

---

### 7.2.10 accuracy-efficiency trade-off on ImageNet

ë‹¤ìŒì€ ImageNet ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨í•œ ì—¬ëŸ¬ modelì˜ MACsì™€ accuracyë¥¼ ë‚˜íƒ€ë‚¸ ë„í‘œë‹¤.

![accuracy-efficiency tradeoff on ImageNet](images/accuracy-efficiency_tradeoff.png)

> ë‹¨, ì‹¤ì œ downstream(ì‚°ì—…)ì—ì„œ í™œìš©í•  ë•ŒëŠ” benchmarkë§Œ ë¯¿ì–´ì„œëŠ” ì•ˆ ëœë‹¤. ì„±ëŠ¥ì´ benchmarkì™€ ì¼ì¹˜í•œë‹¤ëŠ” ë³´ì¥ì€ ì—†ë‹¤.

---